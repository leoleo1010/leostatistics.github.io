<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Statistical distributions</title>
        <style>
            body {
                font-family: 'Arial', sans-serif;
                margin: 0;
                padding: 0;
                background-color: #f4f4f4;
                color: #333;
            }
    
            header {
                background-color: #007acc;
                color: #fff;
                padding: 1em;
                text-align: center;
            }
    
            main {
                display: flex;
                max-width: 800px;
                margin: 20px auto;
                border:groove;
                background-color: #fff;
                box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            }
    
            img {
                max-width: 100%;
                height: 40%;
                margin-top: 20%;
                margin-right: 1%;
            }
            figure{
                max-width: 30%;
                height: 40%;
                margin-top: 10%;
                margin-right: 1%; 
            
            }
    
            .content {
                flex: 1;
                padding: 20px;
            }
    
            h1 {
                color: #007acc;
            }
    
            p {
                line-height: 1.6;
            }
        </style>
        <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    </head>
    <body>
        <header>
            <h1 style="color: white;">Statistical distributions</h1>
        </header>
        <main>
            <div class="content">
                <h2> Meaning </h2>
                <p>
                    A <b>statistical distribution</b>, also known as a <b>probability distribution</b>, is a mathematical function that describes the likelihood of obtaining the possible values that a random variable can take. In other words, it provides a set of probabilities for different outcomes. Statistical distributions are fundamental in statistics and probability theory, and they are used to model and analyze various phenomena in the real world.
                </p>
                <p>There are two main types of statistical distributions: continuous and discrete</p>
                <ul>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Continuous Distribution:</b>
                        A continuous distribution describes variables that can take any value within a given range. The data is not restricted to specific points and can include any value within a specified interval.
                    </li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Discrete Distribution:</b>
                        A discrete distribution describes variables that can only take distinct, separate values. These values are typically counted, and there are gaps between them.
                    </li>
                </ul>
                <p>
                    Understanding statistical distributions is <b>essential for statisticians</b>, data scientists, and researchers as they analyze data, make predictions, and draw conclusions. The choice of an appropriate distribution depends on the nature of the data and the characteristics of the phenomenon being studied.
                </p>
                <p> Also, understanding the <b>characteristics</b> and <b>properties</b> of different distributions is crucial for making statistical inferences, conducting hypothesis testing, and building predictive models in various fields such as finance, biology, engineering, and more.</p>
            </div>
            <img src="meaning.PNG" style="max-width: 40%;
            height: 40%;
            margin-top: 20%;
            margin-right: 1%;" alt="Immagine correlata alla ricerca">
        </main>
        <main>
            <div class="content">
                <h2>Continuous and Discrete: properties</h2>
                <p>In the <b>continuous distribution</b> variables are measured, not counted. The probability of any single point is infinitesimally small, so probabilities are assigned to intervals.</p>
                <p>Graphs are smooth curves.</p>
                <p>Continuous probability distributions have several key properties that characterize their behavior. These properties are fundamental to understanding and working with continuous distributions:</p>
                <ul>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Probability Density Function (PDF):</b>
                        A continuous distribution is described by a probability density function (PDF), denoted as 
                        \(f(x)\),  which represents the probability of the random variable falling within a specific interval. The integral of the PDF over the entire range is equal to 1.
                        \( \int_{-\infty}^{\infty} f(x)dx=1\)
                    </li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Cumulative Distribution Function (CDF):</b>
                        The cumulative distribution function (CDF), denoted as 
                        \(F(x)\), gives the probability that the random variable is less than or equal to a specific value 
                        \(x\). \(F(x)=\int_{-\infty}^{x} f(t)dt\)</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Range of Values:</b>
                        A continuous distribution can take on an infinite number of possible values within a specified range. Unlike discrete distributions, there are no gaps between values.</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Expected Value (Mean):</b>
                        The expected value or mean (μ) of a continuous distribution is a measure of central tendency and is calculated as the integral of 
                        \(x\) multiplied by the PDF. \(μ= \int_{-\infty}^{\infty} x⋅f(x)dx\)</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Variance and Standard Deviation:</b>
                        The variance \((σ^2)\) and standard deviation \((σ)\) quantify the spread or dispersion of the distribution. They are calculated using the second central moment.
                    \(σ^2 = \int_{-\infty}^{\infty} (x−μ)^2 ⋅f(x)dx\)
                    <p>\(σ=\sqrt{σ^2}\)</p></li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Skewness:</b>
                        Kurtosis measures the "tailedness" of the distribution. It indicates whether the distribution is more or less outlier-prone than a normal distribution.
                        <p>\(\text{Skewness} = \frac{\int_{-\infty}^{\infty} (x - \mu)^3 \cdot f(x) \,dx}{\sigma^3}\)</p>
                    </li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Kurtosis:</b>
                        Kurtosis measures the "tailedness" of the distribution. It indicates whether the distribution is more or less outlier-prone than a normal distribution.
                    <p>\(\text{Kurtosis} = \frac{\int_{-\infty}^{\infty} (x - \mu)^4 \cdot f(x) \,dx}{\sigma^4} - 3
                        \)</p></li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Moments:</b>
                        Higher moments provide additional information about the shape of the distribution.
                    <p>\(\text{n-th Moment} = \int_{-\infty}^{\infty} (x - \mu)^n \cdot f(x) \,dx
                        \)</p></li>
                </ul>
                <p> Meanwhile in the <b>Discrete distributions</b>, variables are typically counts of items or events and the probability of specific values can be determined.</p>
                   <p> <b>Discrete probability distributions</b> have several key properties 
                    that characterize their behavior. These properties are fundamental to 
                    understanding and working with discrete distributions. Here are some of the main properties:</p>
                <ul>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Probability Mass Function (PMF):
                    </b>A discrete distribution is described by a probability mass function (PMF), denoted as 
                        \(P(X=x)\), which represents the probability of the random variable taking on a specific value.</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Cumulative Distribution Function (CDF):</b>
                        The cumulative distribution function (CDF), denoted as 
                        \(F(x)\), gives the probability that the random variable is less than or equal to a specific value 
                        \(x\).</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Range of Values:</b>
                        A discrete distribution can only take on a countable number of distinct values.</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Probability Sum Rule:</b>
                        The sum of the probabilities of all possible outcomes in a discrete distribution is equal to 1.
                        \(∑P(X=x)=1\) </li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Expected Value (Mean):</b>The expected value or mean (
                        μ) of a discrete distribution is a measure of central tendency and is calculated as the sum of each value multiplied by its probability.
                        \(μ=∑x⋅P(X=x)\)</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Variance and Standard Deviation:</b>
                        The variance (σ ^2) and standard deviation (σ) quantify the spread or dispersion of the distribution. They are calculated using the second central moment
                        \(\sigma^2 = \sum_{x} (x - \mu)^2 \cdot P(X=x) \)
                        <p>\(\sigma = \sqrt{\sigma^2} \)</p></li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Skewness and Kurtosis:</b> Skewness measures the asymmetry of the distribution, and kurtosis measures the "tailedness" of the distribution. While these concepts are more commonly discussed in the context of continuous distributions, they can also be considered for discrete distributions</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Mode:</b>The mode of a discrete distribution is the value(s) that occur with the highest probability.</li>
                    <li class="list-item" style="padding-bottom: 10px;"><b>Independence:</b>Two random variables in a discrete distribution are considered independent if the occurrence of one event does not affect the occurrence of the other.</li>
                </ul>
            </div>
        </main>
        <main>
            <div class="content" style="height: 1900px;">
                <h2>Simulations</h2>
                <h4>Bernoulli distribution</h4>
                <p>Consider a very simple discrete distribution, called the Bernoulli distribution. This is the distribution for a process in which only two possible outcomes,
                    1 and 0, can occur, with probabilities p and 1 − p, respectively. (They must add up
                    to 1, of course.) The plot of this probability distribution is shown in Fig. 4.9. It is
                    common to call the outcome of 1 a success and the outcome of 0 a failure. A special
                    case of a Bernoulli distribution is the distribution for a coin toss, where the probabilities for Heads and Tails (which we can assign the values of 1 and 0, respectively)
                    are both equal to 1/2.</p>
                    <img src="bernD.PNG" style=" max-width: 50%;height: 10%; margin-top: 0%; margin-left: 20%; padding-bottom: 10px;"  alt="Equation A.26">
                    <p>The Bernoulli distribution is the simplest of all distributions, with the exception
                        of the trivial case where only one possible outcome can occur, which therefore has a probability of 1.</p>
                <h4>Binomial distribution</h4>
                <p>$$P(X = k) = \binom{n}{k} \cdot p^k \cdot (1-p)^{n-k}$$ $$(eq. 4.6)$$
                    In Eq. (4.6), n is the total number of Bernoulli processes, p is the probability of success in each Bernoulli process, and k is the total number of successes
                        in the n processes. (So k can be anything from 0 to n.) Fig. 4.10 shows the binomial
                        distribution for the cases of n = 30 and p = 1/2 (which arises from 30 coin tosses),
                        and n = 30 and p = 1/6 (which arises from 30 die rolls, with a particular one of the
                        six numbers representing success).
                </p>
                <img src="binomD.PNG" style=" max-width: 50%;height: 10%; margin-top: 0%; margin-left: 20%; padding-bottom: 10px;"  alt="Equation A.26">
                <h4>Poisson distribution</h4>
                <img src="Poisson.png" style=" max-width: 50%;height: 12%; margin-top: 0%; margin-left: 20%; padding-bottom: 10px;"  alt="Equation A.26">
                <p>This is<b> the probability mass function,</b>the horizontal axis is the index k, the number of occurrences. λ is the expected rate of occurrences. The vertical axis is the probability of k occurrences given λ. The function is defined only at integer values of k; the connecting lines are only guides for the eye.</p>
                <img src="cumul.PNG" style=" max-width: 50%;height: 12%; margin-top: 0%; margin-left: 20%; padding-bottom: 10px;"  alt="Equation A.26">
                <p>This is<b> the Cumulative distribution function,</b> the horizontal axis is the index k, the number of occurrences. The CDF is discontinuous at the integers of k and flat everywhere else because a variable that is Poisson distributed takes on only integer values.</p>
            </div>
        </main>
        <p><b>LINK FONTI:</b>
            <!-- Primo link -->
         <a href="https://machinelearningmastery.com/statistical-data-distributions/">1° fonte</a>
         <a href="https://sites.nicholas.duke.edu/statsreview/continuous-probability-distributions/">2° fonte</a>
         <a href="https://scholar.harvard.edu/files/david-morin/files/chap4p.pdf">3° fonte</a>
         <a href="https://en.wikipedia.org/wiki/Poisson_distribution#Random_variate_generation">4° fonte</a>

</body>
</html>